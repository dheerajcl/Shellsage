import os
from openai import OpenAI

class DeepSeekLLMHandler:
    def __init__(self, api_key=None):
        self.api_key = api_key or os.getenv('HYPERBOLIC_API_KEY')
        if not self.api_key:
            raise ValueError("HYPERBOLIC_API_KEY environment variable required")
        
        self.client = OpenAI(
            api_key=self.api_key,
            base_url="https://api.hyperbolic.xyz/v1"
        )

    def get_error_solution(self, error_context):
        try:
            response = self.client.chat.completions.create(
                model="meta-llama/Llama-3.3-70B-Instruct",
                messages=[{
                    "role": "system",
                    "content": f"""Analyze terminal errors with MANDATORY format:

**Command**: {error_context['command']}
**Error**: {error_context['error_output']}
**CWD**: {error_context['cwd']}
**Exit Code**: {error_context['exit_code']}

Response MUST contain:
1. ğŸ” Cause: <1-line diagnosis>
2. ğŸ› ï¸ Fix: `[executable command]`
3. ğŸ“š Explanation: <technical reason>
4. ğŸ”’ Prevention: <actionable tip>

Examples:
For 'fastfetc' typo:
ğŸ” Cause: Typo in command name
ğŸ› ï¸ Fix: `fastfetch`
ğŸ“š Explanation: 'fastfetc' not found, correct command is 'fastfetch'
ğŸ”’ Prevention: Use 'apt list fastfetch' to verify installation

For permission denied:
ğŸ” Cause: Missing execute permissions
ğŸ› ï¸ Fix: `chmod +x script.sh`
ğŸ“š Explanation: File lacks executable permission (mode 755 required)
ğŸ”’ Prevention: Always check permissions with 'ls -l'"""
                }, {
                    "role": "user",
                    "content": "Provide analysis for this error:"
                }],
                temperature=0.0,
                max_tokens=500
            )
            return response.choices[0].message.content
        
        except Exception as e:
            return f"Error analysis failed: {str(e)}"